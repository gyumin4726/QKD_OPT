# L=100 GPU 아키텍처 실험 설정

L=100km 거리에서 GPU를 사용한 FT-Transformer 아키텍처 하이퍼파라미터 튜닝 실험. CPU 실험에서 검증된 최적 조합(CLS Token + Scheduler + 정규화)을 기반으로 아키텍처 파라미터 최적화.

## 공통 설정

```python
COMMON_CONFIG = {
    # 기본 파라미터
    'L': 100,                         # 거리 (km)
    'epochs': 200,                    # 훈련 에포크 수
    'batch_size': 128,                # 배치 크기
    'device': 'cuda',                 # 디바이스 (GPU 전용)
    
    # 최적화 설정
    'optimizer': 'Adam',              # 옵티마이저
    'learning_rate': 0.0005,          # 학습률
    'weight_decay': 1e-5,             # 가중치 감쇠
    'dropout_rate': 0.1,              # 드롭아웃 비율
    
    # 학습 기법 (CPU 실험에서 검증된 최적 조합)
    'scheduler': 'ReduceLROnPlateau', # LR 스케줄러
    'scheduler_patience': 10,         # 개선 없을 시 LR 감소 대기 에포크
    'scheduler_factor': 0.5,          # LR 감소 비율
    'p_normalization': True,          # p_mu, p_nu, p_vac 정규화 (합=1)
    'pooling': 'cls',                 # CLS Token 사용
    
    # Early Stopping
    'early_stopping': True,           # Early stopping 사용
    'early_stopping_patience': 30,    # 중단 전 대기 에포크
    'early_stopping_min_delta': 1e-6, # 개선 최소 변화량
    
    # 정규화 및 손실 함수
    'scaler': 'MinMaxScaler',         # 입력/출력 모두 MinMaxScaler
    'gradient_clipping': 1.0,         # Gradient clipping max_norm
    'activation': 'ReLU + Sigmoid'    # 은닉층: ReLU, 출력층: Sigmoid
}
```

## 실험 변수

이 실험에서는 FT-Transformer의 **아키텍처 파라미터**와 **손실 스케일링**을 점진적으로 조정:

| 변수 | 설명 | 실험 범위 |
|------|------|----------|
| `d_embed` | 임베딩 차원 | 32 → 64 → 128 |
| `n_layers` | Transformer 레이어 수 | 3 → 4 |
| `dim_feedforward` | Feedforward 차원 | 128 → 256 |
| `loss_scaling` | 전체 MSE 손실의 배수 | 100 → 10 → 1 |

**참고:** `loss_weight`의 SKR은 모든 모델에서 1000배로 고정

---

## 모델별 설정

### cls_ft_schedule_norm_gpu1.pth

**기본 GPU 모델 (CPU 최적 설정 + GPU)**

```python
{
    'model': 'FT-Transformer',
    'device': 'cuda',
    
    # 아키텍처
    'd_embed': 32,                    # 임베딩 차원
    'n_heads': 4,                     # Attention head 수
    'n_layers': 3,                    # Transformer 레이어 수
    'dim_feedforward': 128,           # Feedforward 차원
    'input_size': 8,                  # 입력 변수 (Y_0 포함)
    'output_size': 9,                 # 8개 파라미터 + SKR
    
    # 학습 설정
    'learning_rate': 0.0005,
    'loss_weight': [1, 1, 1, 1, 1, 1, 1, 1, 1000],  # SKR 가중치 1000배
    'loss_scaling': 100,              # 전체 손실 배수
    'pooling': 'cls',
    'scheduler': 'ReduceLROnPlateau',
    'p_normalization': True
}
```

**특징:** CPU 실험의 최적 조합을 GPU로 이전한 기본 설정

---

### cls_ft_schedule_norm_gpu2.pth

**변경사항:** 임베딩 차원 증가

```python
{
    # ... (공통 설정 동일)
    
    # 아키텍처 변경
    'd_embed': 32 → 64,               # 🔹 임베딩 차원 2배 증가
    'n_heads': 4,
    'n_layers': 3,
    'dim_feedforward': 128,
    
    'loss_weight': [1, 1, 1, 1, 1, 1, 1, 1, 1000],
    'loss_scaling': 100
}
```

**실험 목적:** 임베딩 표현력 강화 효과 검증

---

### cls_ft_schedule_norm_gpu3.pth

**변경사항:** Transformer 레이어 추가

```python
{
    # ... (공통 설정 동일)
    
    # 아키텍처 변경
    'd_embed': 64,
    'n_heads': 4,
    'n_layers': 3 → 4,                # 🔹 레이어 1개 추가
    'dim_feedforward': 128,
    
    'loss_weight': [1, 1, 1, 1, 1, 1, 1, 1, 1000],
    'loss_scaling': 100
}
```

**실험 목적:** 모델 깊이 증가 효과 검증

---

### cls_ft_schedule_norm_gpu4.pth

**변경사항:** 임베딩 및 Feedforward 차원 대폭 증가

```python
{
    # ... (공통 설정 동일)
    
    # 아키텍처 변경
    'd_embed': 64 → 128,              # 🔹 임베딩 차원 2배 증가
    'n_heads': 4,
    'n_layers': 4,
    'dim_feedforward': 128 → 256,     # 🔹 Feedforward 차원 2배 증가
    
    'loss_weight': [1, 1, 1, 1, 1, 1, 1, 1, 1000],
    'loss_scaling': 100
}
```

**실험 목적:** 대형 아키텍처의 표현력 향상 효과 검증

---

### cls_ft_schedule_norm_gpu5.pth

**변경사항:** 손실 스케일링 감소 (100 → 10)

```python
{
    # ... (공통 설정 동일)
    
    # 아키텍처 (gpu4와 동일)
    'd_embed': 128,
    'n_heads': 4,
    'n_layers': 4,
    'dim_feedforward': 256,
    
    # 손실 스케일링 변경
    'loss_weight': [1, 1, 1, 1, 1, 1, 1, 1, 1000],  # SKR 가중치는 여전히 1000배
    'loss_scaling': 100 → 10          # 🔹 전체 손실 배수 감소
}
```

**실험 목적:** 전체 손실 배수를 줄여 학습 안정화 및 파라미터 예측 균형 개선

---

### cls_ft_schedule_norm_gpu6.pth

**변경사항:** 손실 스케일링 정규화 (10 → 1)

```python
{
    # ... (공통 설정 동일)
    
    # 아키텍처 (gpu4, gpu5와 동일)
    'd_embed': 128,
    'n_heads': 4,
    'n_layers': 4,
    'dim_feedforward': 256,
    
    # 손실 스케일링 변경
    'loss_weight': [1, 1, 1, 1, 1, 1, 1, 1, 1000],  # SKR 가중치는 여전히 1000배
    'loss_scaling': 10 → 1            # 🔹 전체 손실 배수를 1로 정규화
}
```

**실험 목적:** 손실 스케일링을 1로 정규화하여 학습 안정성 극대화

---

## 실험 전략

### 1단계: 아키텍처 확장 (gpu1 → gpu4)
- **임베딩 차원**: 32 → 64 → 128 (표현력 강화)
- **레이어 수**: 3 → 4 (모델 깊이 증가)
- **Feedforward 차원**: 128 → 256 (비선형 변환 능력 향상)

### 2단계: 손실 스케일링 조정 (gpu4 → gpu6)
- **loss_scaling**: 100 → 10 → 1 (전체 손실 배수 감소)
- **loss_weight (SKR)**: 1000배 고정 유지
- 학습 안정화 및 gradient 스케일 정규화

## 주요 발견

1. **아키텍처 확장 효과**: `d_embed=128`, `n_layers=4`, `dim_feedforward=256`에서 최적 성능
2. **손실 스케일링 영향**: loss_scaling=1로 정규화 시 학습 가장 안정적
3. **GPU 가속**: CPU 대비 약 10배 빠른 학습 속도
4. **Early Stopping**: 대부분 100~150 에포크에서 조기 종료

## 다음 단계

- GPU 최적 아키텍처를 다른 거리(L=20, L=50)에 적용
- 배치 크기 및 학습률 추가 튜닝
- 데이터 증강 기법 실험 (Y_0 변형 등)
