# L=100 GPU μ•„ν‚¤ν…μ² μ‹¤ν— μ„¤μ •

L=100km κ±°λ¦¬μ—μ„ GPUλ¥Ό μ‚¬μ©ν• FT-Transformer μ•„ν‚¤ν…μ² ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ‹¤ν—. CPU μ‹¤ν—μ—μ„ κ²€μ¦λ μµμ  μ΅°ν•©(CLS Token + Scheduler + μ •κ·ν™”)μ„ κΈ°λ°μΌλ΅ μ•„ν‚¤ν…μ² νλΌλ―Έν„° μµμ ν™”.

## κ³µν†µ μ„¤μ •

```python
COMMON_CONFIG = {
    # κΈ°λ³Έ νλΌλ―Έν„°
    'L': 100,                         # κ±°λ¦¬ (km)
    'epochs': 200,                    # ν›λ ¨ μ—ν¬ν¬ μ
    'batch_size': 128,                # λ°°μΉ ν¬κΈ°
    'device': 'cuda',                 # λ””λ°”μ΄μ¤ (GPU μ „μ©)
    
    # μµμ ν™” μ„¤μ •
    'optimizer': 'Adam',              # μµν‹°λ§μ΄μ €
    'learning_rate': 0.0005,          # ν•™μµλ¥ 
    'weight_decay': 1e-5,             # κ°€μ¤‘μΉ κ°μ‡ 
    'dropout_rate': 0.1,              # λ“λ΅­μ•„μ›ƒ λΉ„μ¨
    
    # ν•™μµ κΈ°λ²• (CPU μ‹¤ν—μ—μ„ κ²€μ¦λ μµμ  μ΅°ν•©)
    'scheduler': 'ReduceLROnPlateau', # LR μ¤μΌ€μ¤„λ¬
    'scheduler_patience': 10,         # κ°μ„  μ—†μ„ μ‹ LR κ°μ† λ€κΈ° μ—ν¬ν¬
    'scheduler_factor': 0.5,          # LR κ°μ† λΉ„μ¨
    'p_normalization': True,          # p_mu, p_nu, p_vac μ •κ·ν™” (ν•©=1)
    'pooling': 'cls',                 # CLS Token μ‚¬μ©
    
    # Early Stopping
    'early_stopping': True,           # Early stopping μ‚¬μ©
    'early_stopping_patience': 30,    # μ¤‘λ‹¨ μ „ λ€κΈ° μ—ν¬ν¬
    'early_stopping_min_delta': 1e-6, # κ°μ„  μµμ† λ³€ν™”λ‰
    
    # μ •κ·ν™” λ° μ†μ‹¤ ν•¨μ
    'scaler': 'MinMaxScaler',         # μ…λ ¥/μ¶λ ¥ λ¨λ‘ MinMaxScaler
    'gradient_clipping': 1.0,         # Gradient clipping max_norm
    'activation': 'ReLU + Sigmoid'    # μ€λ‹‰μΈµ: ReLU, μ¶λ ¥μΈµ: Sigmoid
}
```

## μ‹¤ν— λ³€μ

μ΄ μ‹¤ν—μ—μ„λ” FT-Transformerμ **μ•„ν‚¤ν…μ² νλΌλ―Έν„°**μ™€ **μ†μ‹¤ κ°€μ¤‘μΉ**λ¥Ό μ μ§„μ μΌλ΅ μ΅°μ •:

| λ³€μ | μ„¤λ… | μ‹¤ν— λ²”μ„ |
|------|------|----------|
| `d_embed` | μ„λ² λ”© μ°¨μ› | 32 β†’ 64 β†’ 128 |
| `n_layers` | Transformer λ μ΄μ–΄ μ | 3 β†’ 4 |
| `dim_feedforward` | Feedforward μ°¨μ› | 128 β†’ 256 |
| `loss_scaling` | SKR μ†μ‹¤ κ°€μ¤‘μΉ λ°°μ¨ | 100 β†’ 10 β†’ 1 |

---

## λ¨λΈλ³„ μ„¤μ •

### cls_ft_schedule_norm_gpu1.pth

**κΈ°λ³Έ GPU λ¨λΈ (CPU μµμ  μ„¤μ • + GPU)**

```python
{
    'model': 'FT-Transformer',
    'device': 'cuda',
    
    # μ•„ν‚¤ν…μ²
    'd_embed': 32,                    # μ„λ² λ”© μ°¨μ›
    'n_heads': 4,                     # Attention head μ
    'n_layers': 3,                    # Transformer λ μ΄μ–΄ μ
    'dim_feedforward': 128,           # Feedforward μ°¨μ›
    'input_size': 8,                  # μ…λ ¥ λ³€μ (Y_0 ν¬ν•¨)
    'output_size': 9,                 # 8κ° νλΌλ―Έν„° + SKR
    
    # ν•™μµ μ„¤μ •
    'learning_rate': 0.0005,
    'loss_scaling': 100,              # SKR κ°€μ¤‘μΉ 100λ°°
    'pooling': 'cls',
    'scheduler': 'ReduceLROnPlateau',
    'p_normalization': True
}
```

**νΉμ§•:** CPU μ‹¤ν—μ μµμ  μ΅°ν•©μ„ GPUλ΅ μ΄μ „ν• κΈ°λ³Έ μ„¤μ •

---

### cls_ft_schedule_norm_gpu2.pth

**λ³€κ²½μ‚¬ν•­:** μ„λ² λ”© μ°¨μ› μ¦κ°€

```python
{
    # ... (κ³µν†µ μ„¤μ • λ™μΌ)
    
    # μ•„ν‚¤ν…μ² λ³€κ²½
    'd_embed': 32 β†’ 64,               # π”Ή μ„λ² λ”© μ°¨μ› 2λ°° μ¦κ°€
    'n_heads': 4,
    'n_layers': 3,
    'dim_feedforward': 128,
    
    'loss_scaling': 100
}
```

**μ‹¤ν— λ©μ :** μ„λ² λ”© ν‘ν„λ ¥ κ°•ν™” ν¨κ³Ό κ²€μ¦

---

### cls_ft_schedule_norm_gpu3.pth

**λ³€κ²½μ‚¬ν•­:** Transformer λ μ΄μ–΄ μ¶”κ°€

```python
{
    # ... (κ³µν†µ μ„¤μ • λ™μΌ)
    
    # μ•„ν‚¤ν…μ² λ³€κ²½
    'd_embed': 64,
    'n_heads': 4,
    'n_layers': 3 β†’ 4,                # π”Ή λ μ΄μ–΄ 1κ° μ¶”κ°€
    'dim_feedforward': 128,
    
    'loss_scaling': 100
}
```

**μ‹¤ν— λ©μ :** λ¨λΈ κΉμ΄ μ¦κ°€ ν¨κ³Ό κ²€μ¦

---

### cls_ft_schedule_norm_gpu4.pth

**λ³€κ²½μ‚¬ν•­:** μ„λ² λ”© λ° Feedforward μ°¨μ› λ€ν­ μ¦κ°€

```python
{
    # ... (κ³µν†µ μ„¤μ • λ™μΌ)
    
    # μ•„ν‚¤ν…μ² λ³€κ²½
    'd_embed': 64 β†’ 128,              # π”Ή μ„λ² λ”© μ°¨μ› 2λ°° μ¦κ°€
    'n_heads': 4,
    'n_layers': 4,
    'dim_feedforward': 128 β†’ 256,     # π”Ή Feedforward μ°¨μ› 2λ°° μ¦κ°€
    
    'loss_scaling': 100
}
```

**μ‹¤ν— λ©μ :** λ€ν• μ•„ν‚¤ν…μ²μ ν‘ν„λ ¥ ν–¥μƒ ν¨κ³Ό κ²€μ¦

---

### cls_ft_schedule_norm_gpu5.pth

**λ³€κ²½μ‚¬ν•­:** SKR μ†μ‹¤ κ°€μ¤‘μΉ κ°μ†

```python
{
    # ... (κ³µν†µ μ„¤μ • λ™μΌ)
    
    # μ•„ν‚¤ν…μ² (gpu4μ™€ λ™μΌ)
    'd_embed': 128,
    'n_heads': 4,
    'n_layers': 4,
    'dim_feedforward': 256,
    
    # μ†μ‹¤ κ°€μ¤‘μΉ λ³€κ²½
    'loss_scaling': 100 β†’ 10          # π”Ή SKR κ°€μ¤‘μΉ 10λ°°λ΅ κ°μ†
}
```

**μ‹¤ν— λ©μ :** SKR μ§‘μ¤‘ ν•™μµ μ™„ν™”, νλΌλ―Έν„° μμΈ΅ κ· ν• κ°μ„ 

---

### cls_ft_schedule_norm_gpu6.pth

**λ³€κ²½μ‚¬ν•­:** SKR κ°€μ¤‘μΉ μ™„μ „ λ™μΌν™”

```python
{
    # ... (κ³µν†µ μ„¤μ • λ™μΌ)
    
    # μ•„ν‚¤ν…μ² (gpu4, gpu5μ™€ λ™μΌ)
    'd_embed': 128,
    'n_heads': 4,
    'n_layers': 4,
    'dim_feedforward': 256,
    
    # μ†μ‹¤ κ°€μ¤‘μΉ λ³€κ²½
    'loss_scaling': 10 β†’ 1            # π”Ή λ¨λ“  μ¶λ ¥ λ³€μ λ™μΌ κ°€μ¤‘μΉ
}
```

**μ‹¤ν— λ©μ :** μ™„μ „ κ· λ“± κ°€μ¤‘μΉ ν•™μµ ν¨κ³Ό κ²€μ¦

---

## μ‹¤ν— μ „λµ

### 1λ‹¨κ³„: μ•„ν‚¤ν…μ² ν™•μ¥ (gpu1 β†’ gpu4)
- **μ„λ² λ”© μ°¨μ›**: 32 β†’ 64 β†’ 128 (ν‘ν„λ ¥ κ°•ν™”)
- **λ μ΄μ–΄ μ**: 3 β†’ 4 (λ¨λΈ κΉμ΄ μ¦κ°€)
- **Feedforward μ°¨μ›**: 128 β†’ 256 (λΉ„μ„ ν• λ³€ν™ λ¥λ ¥ ν–¥μƒ)

### 2λ‹¨κ³„: μ†μ‹¤ κ°€μ¤‘μΉ μ΅°μ • (gpu4 β†’ gpu6)
- **loss_scaling**: 100 β†’ 10 β†’ 1
- SKR μ§‘μ¤‘ ν•™μµμ—μ„ κ· ν• ν•™μµμΌλ΅ μ „ν™
- νλΌλ―Έν„° μμΈ΅ μ •ν™•λ„ κ°μ„  λ©ν‘

## μ£Όμ” λ°κ²¬

1. **μ•„ν‚¤ν…μ² ν™•μ¥ ν¨κ³Ό**: `d_embed=128`, `n_layers=4`, `dim_feedforward=256`μ—μ„ μµμ  μ„±λ¥
2. **μ†μ‹¤ κ°€μ¤‘μΉ μν–¥**: SKR κ°€μ¤‘μΉλ¥Ό μ§€λ‚μΉκ² λ†’μ΄λ©΄ νλΌλ―Έν„° μμΈ΅ μ •ν™•λ„ μ €ν•
3. **GPU κ°€μ†**: CPU λ€λΉ„ μ•½ 10λ°° λΉ λ¥Έ ν•™μµ μ†λ„
4. **Early Stopping**: λ€λ¶€λ¶„ 100~150 μ—ν¬ν¬μ—μ„ μ΅°κΈ° μΆ…λ£

## λ‹¤μ λ‹¨κ³„

- GPU μµμ  μ•„ν‚¤ν…μ²λ¥Ό λ‹¤λ¥Έ κ±°λ¦¬(L=20, L=50)μ— μ μ©
- λ°°μΉ ν¬κΈ° λ° ν•™μµλ¥  μ¶”κ°€ νλ‹
- λ°μ΄ν„° μ¦κ°• κΈ°λ²• μ‹¤ν— (Y_0 λ³€ν• λ“±)
